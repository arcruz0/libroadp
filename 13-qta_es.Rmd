# An√°lisis cuantitativo de textos pol√≠ticos {#qta} 

Sebasti√°n Huneeus^[E-mail: lshuneeus\@uc.cl]


### Lecturas recomendadas  {-}

- Salganik, M. J. (2017). *Bit by Bit: Social Research in the Digital Age.* Princeton University Press, Princeton, NJ.

- Silge, J. and Robinson, D. (2017). *Text Mining with R: A Tidy Approach.* O‚ÄôReilly, Sebastopol, CA.

- Steinert-Threlkeld, Z. C. (2018). *Twitter as Data.* Cambridge University Press, Cambridge.

### Paquetes que necesitas instalar {-}

- `tidyverse` [@R-tidyverse], `paqueteadp` [@R-paqueteadp], `lubridate` [@R-lubridate], `skimr` [@R-skimr], `ggwordcloud` [@R-ggwordcloud], `tidytext` [@R-tidytext], `stopwords` [@R-stopwords], `quanteda` [@R-quanteda], `quanteda.textmodels` [@R-quanteda.textmodels], `qdapRegex` [@R-qdapRegex], `stm` [@R-stm], `tidystm` [@R-tidystm], `remotes` [@R-remotes]. 

Este cap√≠tulo est√° dividido en tres secciones, las cuales emplean diferentes estrategias para analizar datos textuales de Twitter. La Subsecci√≥n \@ref(sqta1) cubre la exploraci√≥n del an√°lisis de texto, la Subsecci√≥n \@ref(sqta2) trabaja con Wordfish (una t√©cnica para posicionar textos a lo largo de un eje), mientras que la Subsecci√≥n \@ref(sqta3) cubre el Structural Topic Modeling (STM), que nos ayuda a descubrir temas subyacentes en los datos de texto.

En el estudio de pol√≠ticas contenciosas, #olafeminista, #metoo, #blacklivesmatter y #niunamenos son hashtags que fueron virales y cuentan una rica historia sobre el activismo y la protesta en redes sociales. Usaremos como caso de estudio un ciclo de protesta llamado Ola Feminista, que ocurri√≥ en Chile desde Mayo hasta Junio del 2018. El ciclo de protesta feminista denunci√≥ inequidades de g√©nero estructurales, comenz√≥ como una mobilizaci√≥n de estudiantes en Santiago, y creci√≥ --gradualmente-- expandi√©ndose a demandas m√°s amplias, provenientes de organizaciones feministas y de trabajadores en todo Chile. ^[Para un entendimiento m√°s profundo del alcance de este movimiento, recomendamos el libro editado por la periodista Faride Zer√°n, "Mayo Feminista: La rebeli√≥n contra el patriarcado" [-@zeranMayoFeministaRebelion2018].]

En la primera mitad de este cap√≠tulo, podr√°s aprender c√≥mo usar estad√≠sticas descriptivas b√°sicas para entender c√≥mo los formuladores de pol√≠ticas usan Twitter. Analizaremos c√≥mo los diputados en Chile utilizaron hashtags relacionados al g√©nero durante la #olafeminista. Analizaremos variaciones simples de frecuencia en el uso de hashtags para abordar diferentes niveles de compromiso con el debate en l√≠nea sobre cuestiones feministas y de g√©nero.

En la segunda mitad del cap√≠tulo, aprender√°s c√≥mo usar Wordfish y Structural Topic Modeling (STM), dos t√©cnicas recientes de procesamiento de lenguaje natural (PNL por sus siglas en ingl√©s) utilizadas en ciencia pol√≠tica para miner√≠a de datos sin supervisi√≥n. Mientras que Wordfish nos permitir√° posicionar las coaliciones pol√≠ticas a lo largo de un eje ideol√≥gico izquierda-derecha, el STM nos permitir√° identificar los temas --o grupos de palabras-- m√°s regulares y ver c√≥mo esos t√≥picos est√°n correlacionados a una variable de inter√©s. En nuestro ejemplo, exploraremos la correlaci√≥n entre el g√©nero del diputado y el uso de ciertos hashtags. En general, estas t√©cnicas son grandes herramientas para ganar conocimiento sobre c√≥mo las coaliciones y los formuladores de pol√≠ticas participan digitalmente en una conversaci√≥n pol√≠tica.

En este cap√≠tulo, utilizar√°s una base de datos original con variables de identificaci√≥n para los diputados y diputadas, como lo son el nombre y apellido, distrito, partido pol√≠tico, edad, entre otras. Las variables de identificaci√≥n fueron extra√≠das desde la [p√°gina web oficial de la C√°mara de Diputados](https://www.camara.cl/camara/deputys.aspx#tab). Para la extracci√≥n de datos desde Twitter usamos el paquete `rtweet`, que nos permite acceder libremente a la API de Twitter para descargar informaci√≥n de los usuarios, fechas y hashtags (ver Cap√≠tulo \@ref(web-mining)).

En este tipo de an√°lisis, la tarea m√°s dif√≠cil es reunir y limpiar la base de datos para que se vea "tidy" (ordenada). Afortunadamente, la API de Twitter y paquetes como `rtweet` o `twitter` son muy √∫tiles para manejar la informaci√≥n descargada de una manera simple y ordenada. ^[Para aprender m√°s sobre algunas grandes estrategias de investigaci√≥n en ciencias sociales utilizando datos de Twitter, te recomendamos el cap√≠tulo "Observing Behavior" del libro "Bit by Bit" de Matthew Salganik [-@salganikBitBitSocial2017, ch. 2].] 

## An√°lisis de hashtags pol√≠ticos {#sqta1}

¬øQu√© son los hashtags (#) y c√≥mo est√°n relacionado con la pol√≠tica? Los hashtags son textos que conectan usuarios en una conversaci√≥n digital. Analizarlos nos ayuda a entender c√≥mo, cu√°ndo y por qui√©n estas conversaciones est√°n teniendo lugar. Adem√°s, los hashtags pueden ayudar a la movilizaci√≥n pol√≠tica. De hecho, existe literatura que aborda la protesta social a trav√©s de la viralizaci√≥n de hashtags, como los trabajos recientes que estudian el hashtag-feminismo [@trottConnectedFeministsForegrounding2018] y hashtags de activismo de minor√≠as raciales, como el #blacklivesmatter [@inceSocialMediaResponse2017].^[Una lectura esencial sobre c√≥mo se puede estudiar una crisis pol√≠tica latinoamericana a trav√©s de Twitter es *Political Anatomy of Twitter in Argentina* [-@calvoAnatomiaPoliticaTwitter2015] sobre la estructura de red digital generada tras la muerte del fiscal Alberto Nisman en 2015.]

En general, usar un hashtag indica inter√©s en un t√≥pico, independiente de que uno est√© a favor o en contra de √©l. Por lo tanto, este primer ejercicio no intenta medir los niveles de apoyo, sino que este an√°lisis nos permite identificar aquellos representantes que discuten temas de g√©nero. La organizaci√≥n de la secci√≥n es la siguiente. La primera parte es la exploraci√≥n de la base de datos y un an√°lisis descriptivo bivariado de las frecuencias de los `#`. En la segunda parte, hacemos una comparaci√≥n por g√©nero. Tercero, comparamos el uso de hashtags por coalici√≥n pol√≠tica. En la cuarta parte, veremos la variaci√≥n semanal en el uso de algunos `#`. En la quinta parte, esta variaci√≥n temporal ser√° separada por g√©nero.

### Exploraci√≥n de datos de Twitter

```{r, message=F}
library(tidyverse)
library(tidytext)
```

```{r}
library(paqueteadp)
data("poltweets")
```

Tras cargar la base de datos `poltweets`, la exploramos con `skimr::skim(poltweets)`, como muestra la Figura \@ref(fig:skim-qta). Con esta funci√≥n puedes hacer una exploraci√≥n r√°pida del tama√±o de la base de datos, el n√∫mero de observaciones y variables, y el tipo de variable (car√°cter, n√∫mero entero, factor, etc.). Tambi√©n podemos ver el n√∫mero de valores perdidos, el n√∫mero de categor√≠as o valores que la variable factor asume (`n_unique`), as√≠ como la dispersi√≥n estad√≠stica para las variables cuantitativas (min, max, cuantiles, media y desviaci√≥n est√°ndar). `skimr::skim()` es un buen primer paso que nos permite diagnosticar los datos con los que trabajaremos. En el caso de nuestra base de datos `poltweets`, podemos ver que hay 7 variables de tipo "caracter" y una de tipo "POSIXct", que tambi√©n ayuda a trabajar con fechas.

```{r skim-qta, fig.align='center',echo=FALSE, out.width='100%', fig.cap="Skim de nuestra base de datos."}
knitr::include_graphics("00-images/qta/skim_qta.png")
```

Mira c√≥mo el 75,4% de las filas en la base de datos corresponden a tweets hechos por congresistas. Tambi√©n notamos que hay 29 congresistas mujeres y 93 congresistas hombres en el conjunto de datos.

```{r}
# among tweets:
poltweets %>% count(genero) %>% mutate(freq = n / sum(n))

# deputies' characteristics:
poltweets %>% 
    distinct(nombre_usuario, genero)%>% 
    count(genero) 
```

Tras cargar la base de datos y dar un r√°pido vistazo al tama√±o y las variables inclu√≠das, debemos extraer los hashtags de los tweets utilizando la funci√≥n `unnest_tokens()` de `tidytext`, creando una base de datos "tokenizada" con una fila por hashtag. Luego, simplemente filtramos todas las filas que empiecen con un hashtag (#), dej√°ndonos con una base de datos de un-hashtag-por-fila.

```{r}
poltweets_hashtags <- poltweets %>% 
  unnest_tokens(output = "hashtag", input = "texto", token = "tweets") %>%
  filter(str_starts(hashtag, "#"))
```

Queremos ver las diferencias en c√≥mo los representantes, partidos y coaliciones participan en el debate pol√≠tico sobre g√©nero. Para hacerlo, creamos una nueva variable dummy que toma el valor "1" cada vez que la variable de cadena de caracter coincide con alguna de las expresiones regulares como "femi", "niunamenos", "aborto", "mujer" y "genero":

```{r}
poltweets_hashtags <- poltweets_hashtags %>%
  mutate(fem_hashtag = case_when(str_detect(hashtag, "femi") ~ 1, 
                                 str_detect(hashtag, "niunamenos") ~ 1, 
                                 str_detect(hashtag, "aborto") ~ 1,
                                 str_detect(hashtag, "mujer") ~ 1,
                                 str_detect(hashtag, "genero")~ 1,
                                 TRUE ~ 0)) %>% 
  mutate(fem_hashtag = as.character(fem_hashtag))
```

Vemos que esta es una buena medida para capturar hashtags relacionados al g√©nero y el feminismo. Observa que s√≥lo el 4.1% de las filas contienen hashtag relacionados con g√©nero bajo este criterio y que los tres hashtags m√°s frecuentes son #aborto3causales, #interpelacionaborto3causales y #leydeidentidaddegeneroahora.^[El hashtag `#aborto3causales` est√° relacionado con un debate nacional de larga data: entre 1989 y 2017, Chile ten√≠a una de las pol√≠ticas de aborto m√°s restrictivas del mundo, criminalizando su pr√°ctica sin excepci√≥n. Desde 2017, el aborto en Chile es legal en los siguientes casos: cuando la vida de la madre est√° en riesgo, cuando el feto no sobrevivir√° el embarazo y durante las primeras 12 semanas de embarazos (14 semanas si la mujer es menor de 14 a√±os) en caso de violaci√≥n. El 12 de febrero de 2018, la Norma T√©cnica fue promulgada en el Diario Oficial de la Ley 21.030, que despenaliz√≥ el aborto en tres causales. La norma fue amenazada con derogaci√≥n y modificaci√≥n, lo que gener√≥ una gran cantidad de controversia.]

```{r}
poltweets_hashtags %>% count(fem_hashtag) %>% mutate(freq = n / sum(n))
```

```{r}
poltweets_hashtags %>% 
  filter(fem_hashtag == "1") %>% 
  count(hashtag) %>% 
  arrange(-n) 
```

### Diagn√≥stico visual

Hagamos algunos an√°lisis bivariados agrupando por n√∫mero de tweets por mes, coalici√≥n y g√©nero (Figuras \@ref(fig:qta1), \@ref(fig:qta2), y \@ref(fig:qta4)). 

```{r qta1, fig.cap= "Total number of tweets by month.", echo=F}
library(lubridate)

poltweets_hashtags %>% 
  mutate(by_month = floor_date(as_date(creado_en), 
                               unit = "month", week_start = 1)) %>% 
  ggplot(aes(x = by_month)) + 
  geom_bar() + 
  labs(title = "",
       x = "Month", y = "Number of tweets") +
  scale_x_date(breaks = scales::date_breaks("months"), 
               labels = scales::date_format("%b %y")) + 
  theme(axis.text.x = element_text(angle = 90))
```

```{r qta2, fig.cap= "Total number of tweets by coalicion.", echo=F}
poltweets_hashtags %>% 
  count(coalicion) %>% 
  ggplot(aes(x = fct_reorder(coalicion, -n), y = n)) + 
  geom_col() +
  labs(title = "",
       x = "coalicion", y = "Number of tweets")
```

```{r qta4, fig.cap= "Total number of tweets by genero.", echo=F}
poltweets_hashtags %>%
  count(genero) %>% 
  ggplot(aes(x = fct_reorder(genero, -n), y = n)) + 
  geom_col() +
  labs(title = "",
       x = "genero", y = "Number of tweets") + 
  theme(axis.text.x = element_text(angle = 90))
```

### Hashtags m√°s utilizados

Para ver cu√°les son los hashtags m√°s utilizados, los ordenamos desde los m√°s frecuentes hasta los menos frecuentes. Vemos que el hashtag m√°s utiliazdo es `#cuentapublica`, vinculado al Discurso P√∫blico del Presidente Sebasti√°n Pi√±era, del 21 de mayo, al Congreso. El hashtag `#aborto3causales` es el √∫nico relacionado a g√©nero en el ranking, con 98 menciones. Este hashtag hace referencia a la discusi√≥n sobre la ley de aborto. 

```{r}
poltweets_hashtags %>% 
  count(hashtag, fem_hashtag) %>% 
  arrange(-n) %>% 
  slice(1:20)
```

### Wordclouds (Nubes de palabras)

Una r√°pida e intuitiva manera de representar frecuencias de palabras son las wordclouds (nubes de palabras). Estas representaciones gr√°ficas permiten posicionar en el centro y con letras m√°s grandes los casos que tienen mayor frecuencia. Para eso, utilizamos el paquete `ggwordcloud` para los 35 hashtags m√°s comunes. Tras crear una base de datos de conteo, emplearemos el `geom_text_wordcloud()` con los mapeos est√©ticos "label", "tama√±o" y "color". En la inspecci√≥n visual vemos los tres hashtags sobre g√©nero m√°s utilizados: #aborto3causales, #leydeidentidaddegeneroahora e #interpelacionaborto3causales (Figure \@ref(fig:qta5)). 

```{r}
library(ggwordcloud)

data_hashtags_wordcloud <- poltweets_hashtags %>% 
  count(hashtag, fem_hashtag) %>% 
  arrange(-n) %>% 
  slice(1:35)
```


```{r eval=F}
ggplot(data_hashtags_wordcloud, 
       aes(label = hashtag, size = n, color = fem_hashtag)) + 
  geom_text_wordcloud() +
  scale_size_area(max_size = 8) + # we set a maximum size for the text 
  theme_void()
```

```{r qta5, warning=F, fig.cap= "Wordcloud of the most common hashtags.", echo=F, fig.width=6}
set.seed(1); ggplot(
  data_hashtags_wordcloud %>% 
    mutate(hashtag = if_else(hashtag == "#diputadohugoreyüëë",
                             "#diputadohugorey",
                             hashtag)), 
  aes(label = hashtag, size = n,
      color = fem_hashtag)) + 
  geom_text_wordcloud() +
  scale_color_manual(values = c("darkgrey", "black")) +
  scale_size_area(max_size = 8) + # we set a maximum size for the text 
  theme_void()
```


### Nubes de palabras por grupos

Utilizando la funci√≥n `facet_wrap()`, las nubes de palabras se pueden dividir por variables de inter√©s. Clasificando por g√©nero y coalici√≥n, inmediatamente vemos c√≥mo hashtags como #olafeminista, #agendamujer y #educacionnosexista aparecen s√≥lo entre las cuentas de Twitter de las congresistas. Al enfrentar coaliciones, nos damos cuenta que los tweets del Frente Amplio (FA) usan una alta proporci√≥n de hashtags relacionados con g√©nero, mientras que la coalici√≥n oficialista Chile Vamos (ChV) no usa ning√∫n hashtag (Ver Figuras \@ref(fig:qta6) and \@ref(fig:qta7)). 

```{r eval=F}
ggplot(poltweets_hashtags %>% 
         count(hashtag, genero, fem_hashtag) %>% 
         arrange(-n) %>% 
         group_by(genero) %>% 
         slice(1:20), 
       aes(label = hashtag, size = n, color = fem_hashtag)) + 
  geom_text_wordcloud() +
  scale_size_area(max_size = 6) + 
  facet_wrap(~genero)
```

```{r qta6, warning=F, echo=F, fig.cap= "Wordclouds by genero.", fig.width = 6}
ggplot(poltweets_hashtags %>% 
         mutate(hashtag = if_else(hashtag == "#diputadohugoreyüëë",
                                  "#diputadohugorey",
                                  hashtag)) %>% 
         count(hashtag, genero, fem_hashtag) %>% 
         arrange(-n) %>% 
         group_by(genero) %>% 
         slice(1:20), 
       aes(label = hashtag, size = n, color = fem_hashtag)) + 
  geom_text_wordcloud() +
  scale_size_area(max_size = 6) +
  scale_color_manual(values = c("darkgrey", "black")) +
  facet_wrap(~genero)
```

```{r eval=F}
ggplot(poltweets_hashtags %>% 
         count(hashtag, coalicion, fem_hashtag) %>% 
         arrange(-n) %>% 
         group_by(coalicion) %>% 
         slice(1:20), 
       aes(label = hashtag, size = n, color = fem_hashtag)) + 
  geom_text_wordcloud() +
  scale_size_area(max_size = 6) + 
  facet_wrap(~coalicion, nrow = 3)
```

```{r qta7, warning=F, echo=F, fig.cap= "Wordclouds by coalicion.", fig.width = 5, fig.height=5}
ggplot(poltweets_hashtags %>%
         mutate(hashtag = if_else(hashtag == "#diputadohugoreyüëë",
                                  "#diputadohugorey",
                                  hashtag)) %>% 
         count(hashtag, coalicion, fem_hashtag) %>% 
         arrange(-n) %>% 
         group_by(coalicion) %>% 
         slice(1:20), 
       aes(label = hashtag, size = n, color = fem_hashtag)) + 
  geom_text_wordcloud() +
  scale_color_manual(values = c("darkgrey", "black")) +
  scale_size_area(max_size = 6) + 
  facet_wrap(~coalicion, nrow = 3)
```

### Gr√°ficos de barras

Ahora clasificaremos la frecuencia de los hashtags por g√©nero. Generaremos este gr√°fico en dos pasos. Primero, creamos una tabla con 15 de los hashtags m√°s utilizados entre mujeres y hombres. Luego, crearemos un gr√°fico de barras a√±adiendo el argumento `geom_col()` a la funci√≥n `ggplot()`. Como resultado, veremos los hashtags #aborto3causales y #leydeidentidaddegeneroahora aparecer s√≥lo en las cuentas de las congresistas, mientras que ninguno de estos hashtags relacionados con g√©nero aparecen en cuentas masculinas (Figura \@ref(fig:qta8)). 

```{r}
plot_15 <- poltweets_hashtags %>%
  group_by(genero) %>% 
  count(hashtag, fem_hashtag) %>% 
  arrange(-n) %>% 
  slice(1:15)
```

```{r eval=F}
ggplot(data    = plot_15,
       mapping = aes(x = n, y = reorder_within(hashtag, n, genero), 
                     fill = fem_hashtag)) +
  geom_col()+
  labs(x = "Frequency", y = "", fill = "Hashtag feminista") +
  facet_wrap(~genero, scales = "free", nrow = 2) +
  scale_y_reordered()
```

```{r qta8, warning=F, echo=F, fig.align='left', fig.height=7, fig.cap="Most frequent hashtags by congresswomen (April 1 - June 30)."}
ggplot(data    = plot_15,
       mapping = aes(x = n, y = reorder_within(hashtag, n, genero), 
                     fill = fem_hashtag)) +
  geom_col()+
  labs(x = "Frequency", y = "", fill = "Hashtag feminista") +
  scale_fill_manual(values = c("darkgrey", "black")) +
  facet_wrap(~genero, scales = "free", nrow = 2) +
  scale_y_reordered()
```

Ahora, calculamos y graficamos el estad√≠stico tf-idf, destinado a medir cu√°n importante es una palabra para un documento en una colecci√≥n de documentos. Este estad√≠stico es una combinaci√≥n de la frecuencia del t√©rmino (tf por sus siglas en ingl√©s) y la frecuencia de documento inversa del t√©rmino (idf por sus siglas en ingl√©s), que disminuye su valor en t√©rminos usados comunmente y lo incrementa para palabras que no se utilizan mucho a lo largo de la colecci√≥n de documentos. Observamos que, cuando separamos por grupos, dos hashtags con los m√°s altos tf_idf en el Frente Amplio est√°n relacionados con g√©nero (#leydeidentidaddegeneroahora). 

```{r}
hash_tf_idf <- poltweets_hashtags %>%
  # calculate tf-idf:
  count(coalicion, hashtag, fem_hashtag, sort = T) %>% 
  bind_tf_idf(term = hashtag, document = coalicion, n = n) %>% 
  # get 10 most distinctive hashtags per coalicion:
  arrange(-tf_idf) %>% 
  group_by(coalicion) %>% 
  slice(1:10)
```

```{r eval=F}
ggplot(data    = hash_tf_idf,
       mapping = aes(x = tf_idf,
                     y = reorder_within(hashtag, tf_idf, coalicion), 
                     fill = fem_hashtag)) +
  geom_col() +
  labs(x = "tf_idf", y = "", fill = "Hashtag feminista") +
  facet_wrap(~coalicion, nrow = 3, scales = "free") +
  scale_y_reordered()
```

```{r tf, echo=F, fig.cap="tf-idf statistic, intended to measure how important a word is to a document.", fig.height=7, fig.width=6}
ggplot(data    = hash_tf_idf %>% 
         mutate(hashtag = if_else(hashtag == "#diputadohugoreyüëë",
                                  "#diputadohugorey",
                                  hashtag)),
       mapping = aes(x = tf_idf,
                     y = reorder_within(hashtag, tf_idf, coalicion), 
                     fill = fem_hashtag)) +
  geom_col() +
  labs(x = "tf_idf", y = "", fill = "Hashtag feminista") +
  scale_fill_manual(values = c("darkgrey", "black")) +
  facet_wrap(~coalicion, nrow = 3, scales = "free") +
  scale_y_reordered()
```

### Variaci√≥n temporal en el uso de hashtags

Ciertos hashtags pueden aumentar o disminuir su uso a trav√©s del tiempo, dependiendo del contexto pol√≠tico. Exploraremos la frecuencia semanal de los dos hashtags m√°s frecuentes en nuestro ejemplo. Utilizando el paquete `lubridate`, que trabaja con datos en formato fecha, podemos buscar por tendencias de tiempo. En nuestra base de datos tenemos una variable con una fecha: `creado_en`. Usando esta variable, podemos confirmar que hubo un "peak" de tweets entre el 27 de mayo y el 2 de junio (ver Figura \@ref(fig:qta9)). 

```{r qta9, fig.cap= "Temporal variation in the usage of hashtags."}
hashtags_weekly <- poltweets_hashtags %>% 
  mutate(week = floor_date(creado_en, "week", week_start = 1)) %>% 
  filter(hashtag %in% c("#aborto3causales", 
                        "#leydeidentidaddegeneroahora")) %>% 
  count(hashtag, week)

ggplot(data    = hashtags_weekly,
       mapping = aes(x = week, y = n, 
                     linetype = hashtag, group = hashtag)) +
  geom_point() +
  geom_line() +
  labs(x = "Semana", y = "Uso total semanal", linetype = "Hashtag")
```

### Para resumir

Los hashtags pueden decir mucho sobre un debate pol√≠tico. Podemos observar algunas diferencias evidentes entre el uso de "#" sobre g√©nero. Las congresistas usaron muchos m√°s hashtags como #olafeminista y #agendamujer que sus contrapartes masculinas. En cuanto a las coaliciones, las de izquierda (Frente Amplio y La Fuerza de la Mayor√≠a) los utilizaron m√°s. Sobre la variaci√≥n temporal, la mayor intensidad de menciones de temas relacionados al g√©nero ocurrieron durante la semana del 14 al 20 de mayo, la semana previa al Discurso de Cuenta P√∫blica (21 de mayo), lo que tambi√©n coincidi√≥ con manifestaciones en diversas ciudades del pa√≠s. Vemos que, en t√©rminos relativos, las congresistas estuvieron cinco veces m√°s interesadas en el movimiento feminista, ya que usaron el hashtag #agendamujer 5 veces m√°s que sus contrapartes masculinas durante la semana del 14 al 20 de mayo.

¬øQu√© aprendiste en esta secci√≥n? Te mostramos c√≥mo usar Twitter para analizar fen√≥menos pol√≠ticos. Una vez tengas tu propia base de datos, puedes seguir nuestro an√°lisis paso por paso. Esto ser√° √∫til como punto de partida para  dise√±os explicativos que se pregunten sobre las causas del alineamiento pol√≠tico en diferentes agendas. 

## Wordfish

En esta secci√≥n del cap√≠tulo, emplearemos dos t√©cnicas NLP com√∫nmente usadas en ciencia pol√≠tica para miner√≠a de datos sin supervisi√≥n: Wordfish y Structural Topic Models (STM). Ambos modelos de procesamiento de texto nos permiten resumir muchos documentos diferentes de manera r√°pida y econ√≥mica y pueden complementar otras mediciones descriptivas como la frecuencia de palabras o de hashtags. Como no est√°n supervisados, las clasificaciones se realizar√°n sin utilizar ning√∫n c√≥digo o diccionario previo [@welbersTextAnalysis2017]. Esto tiene la ventaja de ahorrar trabajo en la creaci√≥n manual de c√≥digo, as√≠ como evitar el sesgo propio de quien hace el c√≥digo. Otra ventaja es que no son dependientes del lenguaje de origen, es decir, en principio, se pueden utilizar en cualquier lenguaje. Ambos m√©todos utilizan el enfoque de "bolsa de palabras" ("bag of words"), ya que el orden de las palabras dentro del texto no altera el an√°lisis. Los par√°metros estimados por cada algoritmo pueden ser graficados con `ggplot2`, lo que facilita la interpretaci√≥n visual de los resultados.

La organizaci√≥n de la secci√≥n tiene la siguiente estructura, Primero, haremos una peque√±a limpieza de datos, como remover "palabras vac√≠as" (stopwords) (con un diccionario de stopwords, en este caso, incorporado en Quanteda), caracteres y n√∫meros extra√±os. Luego, aplicaremos el algoritmo Wordfish en los tweets de los parlamentarios chilenos durante el mismo periodo que en la secci√≥n anterior. En la segunda parte, haremos un modelamiento de t√≥picos con STM en el mismo corpus.

### Inspecci√≥n y limpieza de datos

Volvemos a cargar la base de datos `poltweets` y notamos que ahora contiene una serie de variables que son necesarias para el an√°lisis de texto. Ahora usaremos los tweets completos, no s√≥lo los tokens. Tambi√©n necesitamos las variables `id`, necesaria para que cada tweet coincida con quien lo twitte√≥.

```{r}
library(quanteda) # dfm and corpus
library(quanteda.textmodels) # wordfish
library(qdapRegex) # remove non ascii characters
```

Empecemos siempre haciendo un escaneo r√°pido a los datos, como hicimos en la secci√≥n previa. El an√°lisis descriptivo nos permite resumir caracter√≠sticas b√°sicas de la base de datos, como el tipo de las variables y el n√∫mero de caracteres por observaci√≥n, la cantidad de datos perdidos (NA) y el rango de unidades de texto contenidas en cada variable. Exploramos la variable de caracteres que contiene los tweets. Al usar el comando `glimpse()` tenemos una previsualizaci√≥n de cada variable, espec√≠ficamente del tipo y una vista previa de las primeras observaciones.

```{r}
glimpse(poltweets)
```

### Pre-procesamiento

Antes de aplicar el algoritmo, debemos pre-procesar los textos. Esto significa utilizar expresiones regulares para lograr un texto m√°s limpio y ordenado. Utilizaremos expresiones regulares para remover caracteres extra√±os, nombres de usuario, URLs, emojis, adem√°s de cambiarlo todo a min√∫sculas.

```{r}
# function to remove accents
f_remove_accent <- function(x){
  x %>% 
    str_replace_all("√°", "a") %>% 
    str_replace_all("√©", "e") %>% 
    str_replace_all("√≠", "i") %>% 
    str_replace_all("√≥", "o") %>% 
    str_replace_all("√∫", "u") %>% 
    str_replace_all("√±", "n") # also replace "√±", a common letter in Spanish
}

# now pre-process the dataset:
poltweets <- poltweets %>% 
  mutate(texto = texto %>%
           # delete user names (which start with @):
           str_remove("\\@[[:alnum:]]+") %>% 
           # delete URLs:
           str_remove_all("http[\\w[:punct:]]+") %>% 
           # all text to lowercase:
           str_to_lower() %>%
           # remove special characters:
           str_remove_all("[\\d\\.,_\\@]+") %>% 
           f_remove_accent() %>%
           # remove emojis
           rm_non_ascii() 
         )
```

Una vez el texto est√° limpio, queremos agrupar de acuerdo con la variable para la comparaci√≥n. Como estamos interesados en obtener las estimaciones en el nivel de coalici√≥n, agrupamos los textos por coalici√≥n. Ahora, cada coalici√≥n es un documento en la base de datos. Al ordenar por coaliciones, debes colocar los niveles del factor de forma que se parezca a un eje izquierda-derecha.

```{r}
by_coalition <- poltweets %>% 
  group_by(coalicion) %>% 
  summarize(texto = str_c(texto, collapse = " ")) %>%
  ungroup() %>% 
  # reorder the variable:
  mutate(coalicion = fct_relevel(as.factor(coalicion), "FA", "LFM", "ChV"))
```

Para modelar con Quanteda, primero transformamos nuestra base de datos a formato Corpus, y luego a formato DFM (Document-feature Matrix). Esto significa transformar cada documento en filas y las "caracter√≠sticas" como columnas. Hicimos la transformaci√≥n de la base de datos agrupada por coaliciones hacia formato Corpus y luego a DFM. Adicionalmente, aprovechamos el uso de un comando que ayudar√° eliminar n√∫meros, puntuaciones, s√≠mbolos y palabras vac√≠as (conjunciones, art√≠culos, etc.)

```{r}
# Corpus format
poltweets_corpus <- corpus(by_coalition, text_field = "texto")

# DFM format
poltweets_dfm <- dfm(poltweets_corpus,
                     remove_numbers = T, remove_punct = T, 
                     remove_symbols = T, remove = stopwords("spa"))
```

Utilizando `dfm_trim()`, eliminamos aquellas palabras con una frecuencia igual o menor que el quinto percentil y aquellas con una frecuencia igual o mayor que el percentil 95. De esta manera, eliminamos palabras inusuales que est√°n ubicadas en los extremos de la distribuci√≥n de frecuencias, ya que pueden sesgar los resultados del algoritmo.

```{r}
poltweets_dfm_trimmed <- dfm_trim(
  poltweets_dfm, 
  min_docfreq = 0.05, max_docfreq = 0.95, 
  docfreq_type = "quantile" # min 5% / max 95%
)
```

### Wordfish {#sqta2}

Wordfish es un algoritmo que permite hacer una ecala unidimensional de un conjunto de textos [@slapinScalingModelEstimating2008]. Es decir, sirve para ordenar los documentos en un eje unidimensional seg√∫n cu√°n similar son entre s√≠ en el uso de ciertas palabras clave. Este modelamiento asume que el n√∫mero de veces que una palabra es mencionada en un documento sigue una distribuci√≥n de Poisson. Este modelo es extremadamente simple ya que el n√∫mero de veces que una palabra aparecer√° es estimado por un √∫nico par√°metro Œª, que es tanto la media como la varianza de la distribuci√≥n de probabilidad Poisson.

La distribuci√≥n es la siguiente [@prokschPositionTakingEuropean2010]:
  
$$
Wordcount_{ij} \sim Poisson(\lambda_{ij})
$$
                                 
where 
                               
$$
\lambda_{ij} = exp(\alpha_i + \psi_j + \beta_j * \omega_i)
$$
  
El conteo de una palabra $j$ para el documento $i$ sigue una distribuci√≥n de Poisson con par√°metro $Œª$ para la palabra $j$ y el documento $i$. El modelo estima el par√°metro $\lambda_{ij}$, que es la funci√≥n del t√©rmino $\alpha_i$ (el cual es un efecto fijado para los documentos) y el t√©rmino $\psi_j$, que es un efecto fijado para la palabra $j$ - Al ingresar estos efectos fijados, se descuenta el hecho de que algunas palabras pueden aparecer m√°s veces que otras. El par√°metro de inter√©s es $\beta_j$, que captura la importancia de cada palabra $j$ para discriminar las posiciones de $i$ en el eje latente $X$. Por lo tanto, los documentos pueden ser agrupados basado en cu√°n similares son entre ellos, utilizando ciertas palabras.
 
Wordfish tiene dos supuestos fundamentales, primero, que las palabras siempre tienen el mismo significado dentro del texto. Segundo, que los textos son ordenados por una dimensi√≥n latente $X$, que es un eje que articula la diferenciaci√≥n ideol√≥gica de los documentos [@slapinScalingModelEstimating2008]. Sin embargo, la validez de esta suposici√≥n se mantiene en la medida en que el m√©todo es robusto con otras mediciones y que el corpus de textos incluidos en el an√°lisis son representativos de la dimensi√≥n.

En ciencia pol√≠tica, alguno de los trabajos que han utilizado este algoritmo con Twitter es el de Andrea Ceron [-@ceronIntrapartyPolitics1402017], en el cual utiliza las estimaciones de Wordfish para predecir la heterogeneidad ideol√≥gica dentro de los partidos pol√≠ticos italianos, para ver qu√© legislador ser√° elegido como ministro y la probabilidad de que abandonen el partido.

Aplicamos el algoritmo Wordfish al objeto de clase DFM, espec√≠ficamente a Quanteda. Definimos la direcci√≥n del par√°metro $\theta$ -el equivalente de $\beta$-, en este caso, el documento 3 (FA) es el polo positivo y el documento 1 (CHV) es el polo negativo en la dimensi√≥n ideol√≥gica estimada. Tambi√©n, usamos el argumento `sparse = T`, que tambi√©n nos permite trabajar con grandes cantidades de datos, ahorrando poder computacional.
                               
```{r}
wf <- textmodel_wordfish(poltweets_dfm_trimmed,
                         dir = c(3, 1), sparse = T)
```

Graficamos en la Figura \@ref(fig:qta11):
                                 
```{r qta11, fig.align='left', fig.cap="Classification of coalitions by ideological positioning"}
df_wf <- tibble(
  # coalicion labels:
  coalicion = wf[["x"]]@docvars[["coalicion"]],
  # then we extract thetas and their SEs from the mode object:
  theta = wf$theta, 
  lower = wf$theta - 1.96 * wf$se.theta, 
  upper = wf$theta + 1.96 * wf$se.theta
)

df_wf

ggplot(data    = df_wf,
       mapping = aes(x = theta, y = fct_reorder(coalicion, theta),
                     xmin = lower, xmax = upper)) +
  geom_point() +
  geom_linerange() +
  # add vertical line at x=0:
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_x_continuous(limits = c(-1.2, 1.2)) +
  labs(y = "")
```

Vemos que las coaliciones est√°n agrupadas a lo largo de una divisi√≥n izquierda-derecha. El par√°metro de inter√©s $\theta$, equivalente al par√°metro beta, es el par√°metro que discrimina las posiciones de los documentos a partir de la frecuencia de las palabras. Vemos que este par√°metro es consistente con c√≥mo las coaliciones est√°n agrupadas pol√≠ticamente. El m√°s a la derecha, Chile Vamos (ChV), con un $\theta$ de 1.07, se encuentra en un extremo del eje x, por el contrario, el de m√°s a la izquierda, Frente Amplio (FA), con un $\theta$ de -0.91, est√° ubicado en el extremo opuesto.
                      
> **Ejercicio 13A.** Puedes repetir el Wordfish, pero ahora invierte la direcci√≥n del par√°metro $\theta$ en el objeto `wf`. ¬øC√≥mo cambia la distribuci√≥n de los documentos al invertir la direcci√≥n del par√°metro? Ahora repite el ejercicio agrupando por partidos pol√≠ticos.


### ¬øQu√© aprendimos de Wordfish?

Usando los mismos tweets que en la secci√≥n anterior, vimos c√≥mo los mensajes provenientes de los miembros del congreso eran consistentes con una divisi√≥n ideol√≥gica, ordenada en un eje izquierda-derecha. En particular, concluimos que las coaliciones Frente Amplio y Chile Vamos est√°n en extremos opuestos con respecto a sus tweets durante el ciclo de protesta chileno. Sorprendentemente, el algoritmo es capaz de ubicar a las coaliciones chilenas en un eje izquierda-derecha tomando como entrada solo los tweets de los parlamentarios durante los ciclos de protesta, sin ning√∫n tipo de etiquetado manual de los textos. Wordfish es una herramienta poderosa para ser utilizada como un m√©todo de posicionamiento espacial, que se suma al repertorio de otras mediciones de posici√≥n pol√≠tica, como las estimaciones de puntos ideales bayesianos [@barberaBirdsSameFeather2015], roll call y cosponsorship [@alemanComparingCosponsorshipRollCall2009].

## Structural Topic Modeling (STM) {#sqta3}



El modelado de temas es un m√©todo computacional para identificar autom√°ticamente agrupaciones de palabras relevantes en grandes vol√∫menes de textos. Una de las aplicaciones m√°s populares en ciencia pol√≠tica es la Latent Dirichlet Allocation (LDA), desarrollada por @bleiLatentDirichletAllocation2003 y explicada de manera did√°ctica por David Blei en la [Machine Learning Summer School 2009 de la Universidad de Cambridge](https://www.youtube.com/watch?v=DDq3OVp9dNA).

Otro desarrollo √∫til es el modelado de temas estructurales (STM por sus siglas en ingl√©s), una t√©cnica de NLP no supervisada para bucear grandes corpus de textos. La principal innovaci√≥n del STM es que incorpora metadatos en el modelado del tema, por lo que permite a los investigadores descubrir temas y estimar su relaci√≥n con las covariables, mejorando la calidad de las inferencias y la interpretabilidad de los resultados. El algoritmo STM est√° disponible en el paquete `stm` creado por Molly Roberts, Brandon Stewart y Dustin Tingley. Para una revisi√≥n m√°s detallada de este m√©todo, hay una gran cantidad de material en el [sitio oficial del paquete](http://www.structuraltopicmodel.com/).

En esta secci√≥n, analizaremos un subconjunto de nuestros tweets para encontrar los temas m√°s relevantes y ver c√≥mo se correlacionan con las variables de g√©nero y coalici√≥n. Siguiendo el ejemplo de [Julia Silge](https://juliasilge.com/blog/evaluating-stm/), primero haremos todo el preprocesamiento utilizando herramientas "tidy", para luego cargar una base de datos corregida a `stm`.

### Pre-procesamiento

Solo utilizaremos tweets de mayo de 2018:

```{r message=F}
library(tidyverse)
library(tidytext)
library(stm)
library(quanteda)
library(qdapRegex)
```

```{r}
poltweets_onemonth <- poltweets %>% 
  filter(creado_en >= "2018-05-01" & creado_en < "2018-06-01")
```

Como se mencion√≥ anteriormente, debemos comenzar preprocesando los textos. Recuerde que en la subsecci√≥n anterior eliminamos caracteres extra√±os del texto. A continuaci√≥n, crearemos una versi√≥n "tokenizada" de `poltweets_onemonth`, donde cada fila es una palabra contenida en el tweet original, sumado a una columna que nos dice el n√∫mero total de veces que cada palabra se dice en todo el conjunto de datos (solo guardamos las palabras que se mencionan diez o m√°s veces). Justo despu√©s de hacer eso, eliminaremos las palabras vac√≠as (conjunciones, art√≠culos, etc.) usando el paquete `stopwords`. Tenga en cuenta que tambi√©n emplearemos un diccionario "personalizado" de palabras clave, compuesto por los nombres y apellidos √∫nicos de los diputados.

```{r}
# obtain unique names and surnames of deputies
nombres_apellido <- c(poltweets$nombres, poltweets$apellido) %>% 
  na.omit() %>% 
  unique() %>% 
  str_to_lower() %>% 
  f_remove_accent() %>% 
  str_split(" ") %>% 
  flatten_chr()

poltweets_words <- poltweets_onemonth %>% 
  unnest_tokens(word, texto, "words") %>% 
  # remove stop words:
  filter(!word %in% stopwords::stopwords("es", "stopwords-iso")) %>% 
  # remove names/surnames of deputies:
  filter(!word %in% nombres_apellido) %>% 
  # just keep words that are present ten or more times
  add_count(word) %>% 
  filter(n > 10)
```

Eso es todo en t√©rminos de pre-procesamiento! A continuaci√≥n, transformaremos el conjunto de datos tokenizado en un objeto stm utilizando las funciones `cast_dfm()` y `convert()`.

```{r}
poltweets_stm <- poltweets_words %>% 
  cast_dfm(id, word, n) %>% 
  convert(to = "stm")
```

Para estimar la relaci√≥n de los temas y las covariables del documento, debemos agregar los valores de covariable en el objeto `poltweets_stm$meta`. El objeto `metadata` es un marco de datos que contiene los metadatos para cada documento en el objeto stm, que luego se puede usar como el documento "prevalence" -o metadatos-. Tenga en cuenta que para crear el objeto stm_meta, es necesario unirlo mediante la variable id, una columna que contiene un identificador √∫nico para cada tweet. 

```{r}
metadata <- tibble(id = names(poltweets_stm$documents)) %>% 
  left_join(distinct(poltweets, id, coalicion, genero), 
            by = "id") %>%
  as.data.frame()

poltweets_stm$meta <- metadata
```

Ahora tenemos todos los ingredientes necesarios para estimar nuestro structural topic model (modelo de tema estructural), almacenados en el objeto `poltweets_stm`:

```{r}
summary(poltweets_stm)
```

### Diagn√≥sticos

Para estimar un `stm`, es necesario definir de antemano el n√∫mero de temas ($K$). Sin embargo, no hay un n√∫mero "correcto" de temas, por lo que los $K$ apropiados deber√≠an decidirse mirando los datos en s√≠ [@robertsStmPackageStructural2019]. Para hacer eso, debemos entrenar varios modelos y c√°lculos de diagn√≥sticos que nos ayudar√°n a decidir. ¬øQu√© rango de $K$ debemos considerar? En el manual del paquete [@R-stm], los autores ofrecen los siguientes consejos:

> Para corpus cortos centrados en temas muy espec√≠ficos (como experimentos de encuestas), 3-10 temas es un rango de inicio √∫til. Para corporaciones peque√±as (de unos cientos a miles), 5-50 temas es un buen lugar para comenzar. M√°s all√° de estas pautas generales, todo depender√° de la aplicaci√≥n. Aplicaciones anteriores en ciencia pol√≠tica que han trabajado con corpus medianos (10 mil a 100 mil documentos) han encontrado que 60-100 temas funcionan bien. Para grandes corpus" 100 temas es un tama√±o predeterminado √∫til. (p√°g. 61)

Nuestro conjunto de datos tiene 5,647 documentos, por lo tanto, trataremos de 5 a 50 temas. Podemos usar la funci√≥n `searchK()` del paquete `stm` para calcular los diagn√≥sticos relevantes, que almacenaremos en el objeto` stm_search`. Este proceso es computacionalmente costoso y puede tomar varios minutos en una computadora moderna. Si no desea esperar, puede cargar el objeto del paquete del libro (`data(stm_search)`) y continuar.

```{r eval=F}
stm_search <- searchK(documents = poltweets_stm$documents,
                      vocab = poltweets_stm$vocab,
                      data = poltweets_stm$meta,
                      # our covariates, mentioned above:
                      prevalence = ~ coalicion + genero,
                      # 5-50 topics range:
                      K = seq(5, 50, by = 5), 
                      # use all our available cores (be careful!):
                      cores = parallel::detectCores(),
                      # a seed to reproduce the analysis:
                      heldout.seed = 123)
```

```{r message=F, echo=F, eval=F}
data("stm_search")
```

```{r include=F}
stm_search <- politicalds::stm_search
```

A continuaci√≥n, ordenaremos nuestro objeto reci√©n creado y graficaremos sus resultados usando `ggplot2`:

```{r}
diagnostics <- stm_search$results %>% 
  # get a tidy structure to plot:
  mutate_all(flatten_dbl) %>% 
  pivot_longer(-K, names_to = "diagnostic", values_to = "value") %>% 
  # we will only use some diagnostics:
  filter(diagnostic %in% c("exclus", "heldout", "residual", "semcoh")) %>% 
  # give better names to the diagnostics:
  mutate(diagnostic = case_when(
    diagnostic == "exclus" ~ "Exclusividad",
    diagnostic == "heldout" ~ "Held-out likelihood",
    diagnostic == "residual" ~ "Residuos",
    diagnostic == "semcoh" ~ "Coherencia sem√°ntica"
  ))
```

```{r}
ggplot(diagnostics, aes(x = K, y = value)) +
  geom_point() +
  geom_line() +
  facet_wrap(~diagnostic, scales = "free")
```

Aqu√≠ presentamos cuatro de los diagn√≥sticos obtenidos con `searchK()`. Tanto la probabilidad retenida como los residuos (caracter√≠sticas de los modelos, m√°s informaci√≥n en @robertsStmPackageStructural2019) parecen sugerir que aumentar los temas es el enfoque correcto. Sin embargo, en nuestra experiencia, la coherencia sem√°ntica y la exclusividad son los mejores indicadores de la adecuaci√≥n de $K$. La coherencia sem√°ntica es quiz√°s el diagn√≥stico que se correlaciona principalmente con el juicio humano sobre la "calidad del tema" [@ robertsStmPackageStructural2019], es decir, temas que incluyen t√©rminos que tienen sentido tem√°tico. Sin embargo, @roberts_structural_2014 sostiene que la coherencia sem√°ntica se puede lograr f√°cilmente con pocos temas, por lo tanto, se debe considerar conjuntamente con la "exclusividad", esto es, cu√°n distintivos son los t√©rminos del tema en comparaci√≥n con otros temas.

Siguiendo estas definiciones e inspeccionando el gr√°fico anterior anterior, los modelos con K = 10 y K = 25 parecen buenos contendientes. Vamos a estimarlos por separado (si no deseas esperar, puedes volver a cargar los objetos de nuestro paquete `paqueteadp`):

```{r eval=F}
stm_model_k10 <- stm(documents = poltweets_stm$documents,
                     vocab = poltweets_stm$vocab, 
                     data = poltweets_stm$meta, 
                     prevalence = ~ coalicion + genero,
                     K = 10)

stm_model_k25 <- stm(documents = poltweets_stm$documents,
                     vocab = poltweets_stm$vocab, 
                     data = poltweets_stm$meta, 
                     prevalence = ~ coalicion + genero,
                     K = 25)
```

```{r echo=F}
data("stm_model_k10", package = "politicalds")
data("stm_model_k25", package = "politicalds")
```

¬øC√≥mo debemos decidir entre estas dos especificaciones? La exclusividad y la coherencia sem√°ntica presentadas en la gr√°fica anterior son medidas de resumen, por lo que quiz√°s podamos obtener m√°s valor al observar valores espec√≠ficos para cada tema en los dos modelos. En la siguiente Figura \@ref(fig:stm-diag2) graficamos la coherencia sem√°ntica frente a la exclusividad, como lo sugiere @robertsStmPackageStructural2019. En un mundo ideal, nos gustar√≠a que todos los temas sean lo m√°s sem√°nticamente coherentes y exclusivos posible. Si bien no estamos en ese mundo ideal, parece que los temas del modelo K = 10 son mejores en este sentido, ya que el modelo K = 25 tiene bastantes temas que se posicionan como valores at√≠picos, pues tienen baja coherencia sem√°ntica o baja exclusividad (¬°o ambas!) Por lo tanto, continuaremos nuestro an√°lisis utilizando el modelo K = 10.

```{r}
# obtener exclusividad y coherencia sem√°ntica de los t√≥picos dentro de los modelos
diagnostics2 <- tibble(
  exclusivity = c(exclusivity(stm_model_k10), exclusivity(stm_model_k25)),
  semantic_coherence = c(
    semanticCoherence(stm_model_k10, documents = poltweets_stm$documents),
    semanticCoherence(stm_model_k25, documents = poltweets_stm$documents)
  ),
  k = c(rep("K=10", 10), rep("K=25", 25))
)
```

```{r stm-diag2, fig.cap="Coherencia sem√°ntica y exclusividad de los t√≥picos en los dos modelos."}
ggplot(data    = diagnostics2, 
       mapping = aes(x = semantic_coherence, y = exclusivity, shape = k)) +
  geom_point(size = 2) +
  labs(x = "Semantic coherence", y = "Exclusivity", shape = "")
```

### An√°lisis

Hemos elegido un modelo con 10 temas. ¬øC√≥mo se ve? Podemos obtener los t√©rminos principales de cada tema (m√°s sobre lo que esto significa en un segundo) y graficarlos, como se muestra en la Figura \@ref(fig:stm-terms). El gr√°fico tambi√©n ordenar√° los temas en funci√≥n de su proporci√≥n esperada dentro de todo el conjunto de tweets. 

```{r warning=F}
model_terms <- tibble(
  topic = as.character(1:10),
  # obtain the top seven terms:
  terms = labelTopics(stm_model_k10)$prob %>% 
    t() %>% 
    as_tibble() %>% 
    map_chr(str_c, collapse = ", "),
  # expected proportion of each topic in the whole set of tweets:
  expected_proportion = colMeans(stm_model_k10$theta)
) %>% 
  arrange(-expected_proportion)

```

```{r stm-terms, fig.cap="T√≥picos y sus t√©rminos m√°s relevantes.", fig.width=8}
ggplot(data    = model_terms,
       mapping = aes(x = expected_proportion, 
                     y = fct_reorder(topic, expected_proportion),
                     label = terms)) +
  geom_col() +
  geom_text(size = 3, hjust = "inward") + # to use space better
  labs(x = "Expected proportion", y = "Topic")
```

Tenga en cuenta que el Tema 2 es el que se refiere a g√©nero, donde se incluyen las palabras "mujeres", "derechos" y "g√©nero". Podemos usar `labelTopics ()` para obtener m√°s t√©rminos que caracterizan este tema, como se muestra en el resultado a continuaci√≥n. Los t√©rminos con mayor probabilidad son los mismos que utilizamos en el gr√°fico anterior, los m√°s comunes en el tema. Otra medida interesante es "FREX", que selecciona t√©rminos que son distintivos de este tema, en comparaci√≥n con otros (en este caso, las palabras son las mismas). Por √∫ltimo, "Lift" (elevaci√≥n) y "Score" (puntuaci√≥n) se importan de otros paquetes [@R-stm], y tambi√©n pueden ser √∫tiles al describir un tema. En este caso, observe c√≥mo los t√©rminos principales de "Lift" incluyen "olafeminista", uno de los hashtags que discutimos anteriormente.

```{r eval=F}
labelTopics(stm_model_k10, 
            topics = 2) # this is the topic we want to analyze
```

```{r echo=F}
f_labelTopics <- function (x, ...) 
{
  if (names(x)[1] != "topics") {
    for (i in 1:length(x$topicnums)) {
      toprint <- sprintf("Topic %i Top Words:\n\nHighest Prob:\n%s \nFREX:\n%s \nLift:\n%s \nScore:\n%s\n", 
                         x$topicnums[i], 
                         stm:::commas(x$prob[x$topicnums[i], 
                         ]), 
                         stm:::commas(x$frex[x$topicnums[i], ]), stm:::commas(x$lift[x$topicnums[i], 
                         ]), 
                         stm:::commas(x$score[x$topicnums[i], ]))
      cat(toprint)
    }
  }
}

print(f_labelTopics(labelTopics(stm_model_k10, topics = 2)))
```

Con este tema en mente, ahora podemos analizar su relaci√≥n con los metadatos, en nuestro caso, el g√©nero y la coalici√≥n de los diputados: ¬øes m√°s probable que las mujeres y los pol√≠ticos de izquierda twiteen sobre la ola feminista? Como dijimos antes, la capacidad de estimar estas relaciones tema-covariable es una ventaja central de los modelos de temas estructurales. El primer paso es usar `estimateEffect()` para obtener los coeficientes del modelo:

```{r warning=F}
stm_effects <- estimateEffect(
  # c(1:10) means that we want coefficients for all topics in our model
  formula  = c(1:10) ~ coalicion + genero, 
  stmobj   = stm_model_k10,
  metadata = poltweets_stm$meta
)
```

A continuaci√≥n, usamos el paquete `tidystm` ^[`tidystm` necesita ser instalado desde GitHub: `remotes::install_github("mikajoh/tidystm")`.] para extraer los efectos del modelo, a trav√©s de `extract.estimateEffect()`. Comencemos con el g√©nero. Cuando la covariable de inter√©s tiene dos niveles, el argumento `m√©todo = "diferencia"` obtendr√° el cambio en la prevalencia ("prevalence") del tema, cambiando de un valor espec√≠fico a otro. En nuestro caso, la columna "estimate" en el objeto `effect_gender` es el cambio en la prevalencia del tema cuando se comparan congresistas mujeres con congresistas hombres. Existe una estimaci√≥n relativamente grande y positiva para el Tema 2 (como se esperaba), que es significativa en los niveles de confianza habituales. Cabe se√±alar que, para la prevalencia de otros temas (4, 7, 10), el g√©nero parece tener un efecto opuesto (aunque m√°s peque√±o), un hallazgo que podr√≠a ser √∫til en investigaciones futuras.

```{r}
library(tidystm)
```

```{r}
effect_gender <- extract.estimateEffect(x = stm_effects,
                                        covariate = "genero",
                                        method = "difference",
                                        cov.value1 = "Femenino",
                                        cov.value2 = "Masculino",
                                        model = stm_model_k10)
effect_gender %>% arrange(-estimate)
```

Es posible graficar estos resultados usando `ggplot2`, una gran ventaja del paquete `tidystm`, que se muestra en la Figura \@ref(fig:stm-effects):

```{r stm-effects, fig.cap="Effect of genero on topic prevalence."}
ggplot(effect_gender,
       aes(x = estimate, xmin = ci.lower, xmax = ci.upper, 
           y = fct_reorder(as.character(topic), estimate))) +
  # a√±adir l√≠nea de efecto nulo
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_linerange() +
  # central la l√≠nea de efecto nulo
  scale_x_continuous(limits = c(-0.075, 0.075)) +
  labs(x = "Estad√≠stico para la diferencia Femenino - Masculino", 
       y = "T√≥pico")
```

Podemos repetir el an√°lisis anterior para la otra covariable en nuestro modelo, obteniendo la diferencia en la prevalencia del tema entre la coalici√≥n de m√°s izquierda (FA o Frente Amplio) y la coalici√≥n de m√°s derecha (ChV o Chile Vamos). Como se esperaba, el modelo estima que los pol√≠ticos de izquierda tend√≠an -probabil√≠sticamente- a twitear m√°s sobre la ola feminista (Tema 2).

```{r}
effect_coalition_diff <- extract.estimateEffect(x = stm_effects,
                                                covariate = "coalicion",
                                                method = "difference",
                                                cov.value1 = "FA",
                                                cov.value2 = "ChV",
                                                model = stm_model_k10)
effect_coalition_diff %>% 
  filter(topic == 2)
```



> **Ejercicio 13B.** Grafica los efectos de la covariable de coalici√≥n, mostrando la diferencia entre la coalici√≥n de derecha (ChV) y las otras (FA y LFM).
>
> **Ejercicio 13C.** Agregue los 7 t√©rminos principales para cada tema a la Figura \@ref(fig:stm-effects). *Consejo: puede usar `left_join()` para fusionar las dos bases de datos de inter√©s.

### Observaciones finales

Las comunicaciones pol√≠ticas en ciclos de protesta tienen claras implicancias en el dominio digital. En esta secci√≥n hemos demostrado que el an√°lisis de texto automatizado de tweets pol√≠ticos captura variaciones en la forma en que se twittea, particularmente, en c√≥mo las congresistas parecen estar m√°s correlacionadas con ciertos temas, en este caso el tema 2, relacionado con g√©nero. STM es una de las t√©cnicas de NLP m√°s recientes utilizadas en ciencia pol√≠tica para miner√≠a de texto sin supervisi√≥n. Sin embargo, a pesar del claro beneficio del uso de la miner√≠a de texto, estas t√©cnicas deben usarse con precauci√≥n ya que la interpretabilidad de los temas es sensible en muchas decisiones como la K (n√∫mero de temas para un modelo dado) y la limpieza del texto.



